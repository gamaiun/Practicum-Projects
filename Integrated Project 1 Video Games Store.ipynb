{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Data = https://code.s3.yandex.net/datasets/games.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFy1ZX7v_pBy"
   },
   "source": [
    "# General\n",
    "\n",
    "Online store Ice, which sells video games all over the world wants to determine whether a game succeeds or not. This will allow Ice to spot potential big winners and plan advertising campaigns.\n",
    "\n",
    "We will analyze historical data and provide recomendations how to plan an advert campaign for the next year.\n",
    "\n",
    "We will start by preparing and cleaning the data.\n",
    "\n",
    "We will then analyze the data and look for distributions and patterns, find the winning scenarios, display charts to demonstrate our case.\n",
    "\n",
    "We will continue with creating a user profile for each region and test 2 hypotheses:\n",
    "\n",
    "1. *Average user ratings of the Xbox One and PC platforms are the same.*\n",
    "\n",
    "2. *Average user ratings for the Action and Sports genres are different.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LzLa1aIiCgA4",
    "outputId": "6f20bf29-65a6-462d-a2d6-8ae40384c313"
   },
   "outputs": [],
   "source": [
    "# Loading all the libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import set_matplotlib_formats\n",
    "from scipy import stats \n",
    "import matplotlib_inline.backend_inline\n",
    "import math\n",
    "import random\n",
    "\n",
    "# If error in \"import sidetable\", please uncomment the following line:\n",
    "!pip install sidetable\n",
    "\n",
    "import sidetable\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "### These lines will make the graphs much crisper\n",
    "\n",
    "if isinstance('svg', str):\n",
    "   ipython_format = ['svg']\n",
    "   matplotlib_inline.backend_inline.set_matplotlib_formats(*ipython_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "giPdof40Cklm"
   },
   "outputs": [],
   "source": [
    "# Load the data files into raw_data df.\n",
    "\n",
    "try:\n",
    "  raw_df = pd.read_csv(\"/content/drive/MyDrive/Practicum/Module_1/Integrated Project_1/games.csv\", )\n",
    "except: \n",
    "  raw_df = pd.read_csv(\"/datasets/games.csv\",)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQLqOL8F_m16"
   },
   "source": [
    "\n",
    "Let's take a first look at our file:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "id": "nBG6_CjZRTUX",
    "outputId": "414a0fc1-a01e-4c2e-bad8-e45daff93972"
   },
   "outputs": [],
   "source": [
    "raw_df.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 863
    },
    "id": "llnv-L3sDJTC",
    "outputId": "72d04e72-9f0e-46cc-a36b-c6f753c3a129"
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"*********************************************\")\n",
    "print(\"****************** ＩＮＦＯ ******************\")\n",
    "print(\"*********************************************\")\n",
    "print(\" \")\n",
    "raw_df.info()\n",
    "print(\" \")\n",
    "print(\"*********************************************\")\n",
    "print(\"**************** NANS COUNT *****************\")\n",
    "print(\"*********************************************\")\n",
    "print(\" \")\n",
    "raw_df.stb.missing(style=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "id": "mm86Xh08RyRc",
    "outputId": "084f4ba6-98d2-4c12-e6a7-9e5f5bb97e15"
   },
   "outputs": [],
   "source": [
    "print(\"*********************************************\")\n",
    "print(\"*********     NUMERIC STATS      ************\")\n",
    "print(\"*********************************************\")\n",
    "print(\" \")\n",
    "raw_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "Li9euCtbSHrn",
    "outputId": "a3e68832-0221-40fa-de17-6f0148c961c2"
   },
   "outputs": [],
   "source": [
    "print(\"*********************************************\")\n",
    "print(\"*********     OBJECT STATS      *************\")\n",
    "print(\"*********************************************\")\n",
    "print(\" \")\n",
    "raw_df.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uBs-hQXiyele",
    "outputId": "295253c2-27a8-4ea0-c91e-0f1c15fdd6ba"
   },
   "outputs": [],
   "source": [
    "# searching for duplicates \n",
    "\n",
    "print(\"There are\", raw_df.duplicated(subset=['Name']).sum(), \"duplicates in Name colums.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l17eUK3qEYYx"
   },
   "source": [
    "Running our first lines of code we notice several things:\n",
    "\n",
    "This is 11X16715 dataset with object and float columns. The dataset has several issues worth mentioning: \n",
    "\n",
    "1. User_Score column is dtype object (should be float).\n",
    "\n",
    "2. **Missing values in**\n",
    "\n",
    " * Critic_Score\t(8,578)\t\n",
    " * Rating\t(6,766)\t\n",
    " * User_Score\t(6,701)\n",
    " * Year_of_Release\t(269)\n",
    " * Name\t(2)\t\n",
    " * Genre\t(2)\n",
    "\n",
    "3. Column names should be lowercase.\n",
    "\n",
    "4. 50% of the games are from 2007 and older. \n",
    "\n",
    "5. Multiple instances of \"tbd\" str in user_score. It prevents us from using it as floats.\n",
    "\n",
    "\n",
    "Let's start solving these problems, first by renaming the columns to lowercase:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v8phC87mTLso",
    "outputId": "e1b88801-e9cf-4e85-ba77-13ad08600da3"
   },
   "outputs": [],
   "source": [
    "raw_df.columns = raw_df.columns.str.lower()\n",
    "\n",
    "# Check:\n",
    "raw_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJRzdQKxTzcv"
   },
   "source": [
    " Solved. Now let's think what to do with the Nans:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B7ivYXms0qgM",
    "outputId": "2cc72bff-8055-4cd5-aaf3-2c6ee211cbeb"
   },
   "outputs": [],
   "source": [
    "print(\"Since we have \", len(raw_df.name.unique()), \"unique game names in\", len(raw_df), \"instances.\")\n",
    "print(\"will it be possible to asign the\",raw_df.user_score.isna().sum(), \"nans in user_score and\", raw_df.critic_score.isna().sum(), \"of critic_score nans?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAIfAXBT1zgl"
   },
   "source": [
    "In many cases we have the same game repeating again and again on different platforms. Let's check if by grouping the instances by name and year_of release we will also get the same scores and ratings. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "_7Kfyq_48x0e",
    "outputId": "5fdf79b9-52d0-498c-dafa-b889e61bb984"
   },
   "outputs": [],
   "source": [
    "# Let's check a random game from a list, if you get less than 1 instance, run this cell again\n",
    "\n",
    "# Let's choose instances that have ratings and name duplicates\n",
    "proper_instances = raw_df[(raw_df.rating.notna()) & raw_df.name.duplicated() & raw_df.year_of_release.duplicated()]\n",
    "\n",
    "# Let's choose and printa random game.\n",
    "random_name = proper_instances.name.iloc[random.randrange(0,100)]\n",
    "random_game = proper_instances[proper_instances.name == random_name]\n",
    "random_game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5fCCaFzhiT9s"
   },
   "source": [
    "**My Comment. v.1 DONE.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SxkbHB1n8yRc"
   },
   "source": [
    "By runnung the above cell several times we can see that although the name of the game and the year of the release are the same, the critic score and the user score are **platform dependent** and therefore **different**. \n",
    "\n",
    "Ratings, on the other hand are the same across all platforms, since the games are rated by the Entertainment Software Rating Board (ESRB).\n",
    "\n",
    "**It means that we SHOULD NOT blindly asign scores based on names and years, but we CAN use it to asign ratings.**\n",
    "\n",
    "Let's do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "id": "T92geDto0qnv",
    "outputId": "a80e1b40-c86e-4416-9481-46c376df20bd"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Let's drop all the Nans in ratings:\n",
    "\n",
    "na_ratings_dropped = raw_df.dropna(subset =[\"rating\"])\n",
    "na_ratings_dropped.sample(5)\n",
    "\n",
    "# Let's drop the duplicates of name and year_of_release, since all platforms got the same rating per game.\n",
    "\n",
    "duplicates_dropped = na_ratings_dropped.drop_duplicates(subset=['name', \"year_of_release\"], keep = \"first\") \n",
    "\n",
    "# We are left with unique name+year instances.:\n",
    "\n",
    "duplicates_dropped.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xcyyRUgidVnm",
    "outputId": "5213b98d-ea1a-4fea-96e0-29a982008fbd"
   },
   "outputs": [],
   "source": [
    "# Let's check that we don't have duplicates (games that have the same name AND year)\n",
    "\n",
    "print(\"We have\", duplicates_dropped.duplicated(subset = [\"name\", \"year_of_release\"]).sum(), \"duplicates in this df.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AEfH2Gi3epj1"
   },
   "outputs": [],
   "source": [
    "# Let's create two dicts:\n",
    "\n",
    "names_years_dict = duplicates_dropped.set_index('name')['year_of_release'].to_dict()\n",
    "\n",
    "names_ratings_dict = duplicates_dropped.set_index('name')['rating'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "id": "aDNSIg7ejjj-",
    "outputId": "e64c877b-a284-4b3c-a943-6be50a97c414"
   },
   "outputs": [],
   "source": [
    "# Now let's create a new df called nans_in_ratings:\n",
    "\n",
    "nans_in_rating = raw_df[raw_df.rating.isna()]\n",
    "\n",
    "# Check:\n",
    "nans_in_rating.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ziYAdXghffRf"
   },
   "outputs": [],
   "source": [
    "# Let's create a list:\n",
    "restored_ratings = []\n",
    "\n",
    "# Error handler\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# And now let's asign ratings to the instances that are missing their ratings:\n",
    "\n",
    "for key, value in names_years_dict.items():\n",
    "    nans_in_rating[(nans_in_rating.name == key) & (nans_in_rating.year_of_release == value)][\"rating\"] = names_ratings_dict[key]\n",
    "    restored_ratings.append(names_ratings_dict[key])\n",
    "\n",
    "nans_in_rating[\"restored_ratings\"] =  pd.Series(restored_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "glFggvMqffUf",
    "outputId": "ae11d0de-0973-43e3-fd7a-0432016980f0"
   },
   "outputs": [],
   "source": [
    "print(\"We have succesfully restored\", nans_in_rating.restored_ratings.notna().sum(), \"ratings!\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "id": "kktvEKJxffaA",
    "outputId": "0a28f7c9-b6fc-4a05-9cd4-ab0d1ed80d06"
   },
   "outputs": [],
   "source": [
    "\n",
    "restored = nans_in_rating.drop([\"rating\"], axis = 1)\n",
    "\n",
    "restored.rename(columns = {\"restored_ratings\" : \"rating\"}, inplace = True)\n",
    "\n",
    "restored.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "id": "UWBzC18PAQ90",
    "outputId": "7c9f70e4-b84b-4e87-c3f5-1b020ea0c5ad"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Let's run a check\n",
    "clean_df =pd.merge(raw_df, restored[\"rating\"], left_index=True, right_index=True, how = \"outer\" )\n",
    "print (\"We have\", clean_df.rating_x.notna().sum(), \"valid instances in ratings_x and\", clean_df.rating_y.notna().sum(), \"in ratings_y.\"  )\n",
    "\n",
    "# Let's unite the columns\n",
    "clean_df[\"rating\"] = clean_df.apply(lambda x: x['rating_y'] if pd.isnull(x['rating_x']) else x['rating_x'], axis=1)\n",
    "print(\"We moved the ratings from y to x. Now we have\",  clean_df.rating.notna().sum(), \"valid instances ratings in column rating.\")\n",
    "\n",
    "# Let's get rid of x and y.\n",
    "clean_df.drop([\"rating_x\", \"rating_y\"], axis = 1, inplace =True)\n",
    "\n",
    "\n",
    "print(\" \")\n",
    "clean_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gc80kTRk-3n9"
   },
   "source": [
    "#### FIX :  Now let's fix the remaining Nans in our rating column by asigning \"NA\" value to the nans.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sSzWyfFR-29Y"
   },
   "outputs": [],
   "source": [
    "clean_df.rating.fillna('NA', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "rhSPBT5xGm1j",
    "outputId": "b569e760-1f75-4eca-8710-e6cfc419cc01"
   },
   "outputs": [],
   "source": [
    "clean_df.stb.missing(style=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-RQzo-vIapU"
   },
   "source": [
    "The rating column nans dropped from 40.4% to 29%.  We have successfully restored 11% of the ratings. But can we do the same thing with the critic_score and user_score? Yes and No. \n",
    "\n",
    "As already mentioned, unlike the ratings that are published by external body (ESRB), the critic score and user score are **platform specific**. Each platform has it's own audience, region of influence, number of players e.c. \n",
    "\n",
    "Arithmetically calculating the mean of the user_score of a game X across all platforms and simply asigning that number to a Nan -  wouldn't be much of a \"cleaning of a data\",since we would be ignoring all the factors involved. \n",
    "\n",
    "We advise against such practice and encourage to work with a quality data. It might be a small sample of the dataset, but it's values are not polluted by our \"calculations\", preconceptions and biases. **When analyzing data we should analyze DATA, and nothing else.**\n",
    "\n",
    "Let's see how many instances are still missing ALL THREE tables (user_score, critic_score, rating)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wY9_j264neT4"
   },
   "source": [
    "\"Tbd\" in user_score column stands for \"to be determined\". At first we might think that this is an indication of a relatively new games, for which there is no user_score yet. But if we check the distribution of the tbds across the years we can see that this is not the case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5beAmyLEKM_T",
    "outputId": "2ceeea33-0890-4925-da39-634b4597f7d0"
   },
   "outputs": [],
   "source": [
    "\n",
    "raw_df[raw_df.user_score ==\"tbd\"][\"year_of_release\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N9q0-i1hKgwO"
   },
   "source": [
    "Some of the games are very old, and still missing the user_score. Meaning that the *tbd* is more of a **placeholder for unknown data**. User scores, as already mentioned before, can not be \"calculated\". Any mean/median will only skew the data. \n",
    "\n",
    "What we can restore is the Nans in the *year of release* column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MR7AgHwSBi58"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Let's clean the years and save in new df\n",
    "na_years_dropped = raw_df.dropna(subset =[\"year_of_release\"])\n",
    "\n",
    "# Let's drop the duplicates of name + year.\n",
    "duplicated_years_dropped = na_years_dropped.drop_duplicates(subset=['name', \"year_of_release\"], keep = \"first\") \n",
    "\n",
    "# Let's create a new name_years dict and save names/years paires.\n",
    "new_name_year_dict =  duplicated_years_dropped.set_index('name')['year_of_release'].to_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7EtpAatSPn_U"
   },
   "source": [
    "Now let's create the dataset we want to \"heal\", to restore the years:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "id": "fTpXKAl_Ptle",
    "outputId": "08f87afc-6a98-452a-836c-c903e799dc7d"
   },
   "outputs": [],
   "source": [
    "# Let's create a data with nans in year_of_release\n",
    "nans_in_year_of_release = raw_df[raw_df.year_of_release.isna()]\n",
    "nans_in_year_of_release.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lHLU0xkoPv4k"
   },
   "source": [
    "Now lets' asign the missing years from the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AtK_YjOk-wOZ",
    "outputId": "4b84e7de-a20f-4a67-890b-3367b27ac1a8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Let's create a list:\n",
    "restored_years = []\n",
    "\n",
    "# Error handler\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# And now let's asign years to the instances that are missing their years:\n",
    "\n",
    "for key, value in new_name_year_dict.items():\n",
    "    nans_in_year_of_release[nans_in_year_of_release.name == key][\"year_of_release\"] = new_name_year_dict[key]\n",
    "    restored_years.append(new_name_year_dict[key])\n",
    "\n",
    "nans_in_year_of_release[\"restored_years\"] =  pd.Series(restored_years)\n",
    "\n",
    "print(\"We have succesfully restored\", nans_in_year_of_release.restored_years.notna().sum(), \"instances.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aW_7IZIWDMH1"
   },
   "source": [
    "Our instances are stored in \n",
    "*nans_in_year_of_release/restored_years* column. Let's move it to the main df. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "Phmpa8PkDpH0",
    "outputId": "f9cc9620-2bf7-47ed-a7d6-6461b2fbe99f"
   },
   "outputs": [],
   "source": [
    "\n",
    "restored_years = nans_in_year_of_release.drop([\"year_of_release\"], axis = 1)\n",
    "\n",
    "restored_years.rename(columns = {\"restored_years\" : \"year_of_release\"}, inplace = True)\n",
    "\n",
    "restored.sample(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHgv9__3RtNi"
   },
   "source": [
    "Let's merge the restored data with our clean_df in a new clean_df_2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "e5OM6gtIEKR_",
    "outputId": "0696963a-7e08-40a9-bb41-cf0ae6a86d70"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Let's run a check\n",
    "clean_df_2 =pd.merge(clean_df, restored_years[\"year_of_release\"], left_index=True, right_index=True, how = \"outer\" )\n",
    "print (\"We have\", clean_df_2.year_of_release_x.isna().sum(), \"nans instances in year_of_release_x and\", clean_df_2.year_of_release_y.notna().sum(), \" restored years in year_of_release_y.\"  )\n",
    "\n",
    "# Let's unite the columns\n",
    "clean_df_2[\"year_of_release\"] = clean_df_2.apply(lambda x: x['year_of_release_y'] if pd.isnull(x['year_of_release_x']) else x['year_of_release_x'], axis=1)\n",
    "print(\"We moved the ratings from y to x. Now we only have\",  clean_df_2.year_of_release.isna().sum(), \"nans in column year_of_release.\")\n",
    "\n",
    "# Let's get rid of x and y.\n",
    "clean_df_2.drop([\"year_of_release_x\", \"year_of_release_y\"], axis = 1, inplace =True)\n",
    "\n",
    "print(\" \")\n",
    "clean_df_2.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DxseOjVGGRoS"
   },
   "source": [
    "Great! We succesfully restored 175 missing years.\n",
    "\n",
    "Let's create a new column with the total sales (the sum of sales in all regions) for each game and put these values in a separate column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "id": "s-JwlzrqPF50",
    "outputId": "c569f07d-376c-48f3-f4b9-70dacd8cfc71"
   },
   "outputs": [],
   "source": [
    "clean_df_2[\"total_sales\"] = clean_df_2[[\"na_sales\",\"eu_sales\", \"jp_sales\",\"other_sales\"]].sum(axis = 1)\n",
    "clean_df_2.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_ov8Ka072jc"
   },
   "source": [
    "# Analyzing the data\n",
    "\n",
    "### Question: **How many games were released in different years. Is the data for every period significant?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pP1E7Wi-7tkl",
    "outputId": "8cdeb933-bbcf-4eb1-f7df-c2883d2767d9"
   },
   "outputs": [],
   "source": [
    "clean_df_2.stb.freq([\"year_of_release\"], style=True, cum_cols = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O71QTMVnMK5U"
   },
   "source": [
    "(*multiple zeros in years are due to the factr that we did not converted the years to ints, since we still have nans in our data)*. \n",
    "\n",
    "The table above shows the distribution of games across the years. From 1980 to 2016 the most \"hot\" year in the game industry was 2008 with 1,448 (8.41%) games. In 1980 - there were only 9 games. \n",
    "\n",
    "Just by looking at the numbers we can see an uptrend dinamit that reached it's peak in 2008-2009. The first 14 years (from 1980 to 1994) have less than 1% of number of games per year, whereas between 2005  - 20010 the ranges are between 5.7% - 8.7%.\n",
    "\n",
    "Let's show this on a graph.\n",
    "\n",
    "To do so we must first drop nans the years column as it will cause are erros in the next step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yL3Gr7sUZGEk",
    "outputId": "92018aea-254e-4cf4-9739-819ffc307865"
   },
   "outputs": [],
   "source": [
    "# New df with no nans in years\n",
    "clean_df_3 = clean_df_2[clean_df_2.year_of_release.notna()]\n",
    "\n",
    "print(\"Now, we have\", clean_df_3.year_of_release.isna().sum(), \"nans in years column.\")\n",
    "print(\" \")\n",
    "# Converting object to ints\n",
    "clean_df_3.year_of_release = clean_df_3.year_of_release.astype(\"int\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "pf2h_wtEdTU2",
    "outputId": "881514d7-94f6-41c2-82b6-1f79067238d8"
   },
   "outputs": [],
   "source": [
    "print(\"Let's see that table again:\")\n",
    "print(\" \")\n",
    "\n",
    "df=clean_df_3[['year_of_release','name']].groupby(['year_of_release']).count().sort_values(by='name', ascending=False).reset_index()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ESIeSlwWS4C4"
   },
   "source": [
    "Let's see how it looks like on the graph: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "id": "CPzSm53wXbXc",
    "outputId": "be0f599a-1706-478a-ab2d-f46e41b8e5db"
   },
   "outputs": [],
   "source": [
    "\n",
    "fig,ax=plt.subplots(figsize=(12,6))\n",
    "ax.vlines(x=df.year_of_release, ymin=0, ymax=df.name, color='purple', alpha=0.7, linewidth=2)\n",
    "ax.scatter(x=df.year_of_release, y=df.name, s=75, color='black',alpha=0.7)\n",
    "plt.xlabel(\"YEARS\")\n",
    "plt.ylabel(\"NUMBER OF GAMES PER YEAR\")\n",
    "plt.title(\"Distribution of games per year between 1980 and 2016\")\n",
    "\n",
    "ax.set_xticks(df.year_of_release)\n",
    "ax.set_xticklabels(df.year_of_release,rotation=90)\n",
    "# ax.axhline(y=300)\n",
    "\n",
    "for row in df.itertuples():\n",
    "    ax.text(row.year_of_release, row.name+30, s=row.name)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FpSkuT5qTE5E"
   },
   "source": [
    "The dinamics we mentioned earlier is clearly shown on the graph. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xafRipqLXhm6"
   },
   "source": [
    "\n",
    "\n",
    "### Question: **How sales varied from platform to platform. Choose the platforms with the greatest total sales and build a distribution based on data for each year.**\n",
    "\n",
    "In order to answer this question, let's choose top 5 game sellers in the industry, based on the total sales.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "pGWP5aaSQiAt",
    "outputId": "44ae7812-88dd-486a-a524-4ed0cf59fe2a"
   },
   "outputs": [],
   "source": [
    "# First by grouping on names and summing the total sales.  \n",
    "unique_games = clean_df_2.groupby(\"platform\").agg({\"total_sales\" : \"sum\"})\n",
    "\n",
    "# Choosing the top 5 total sellers.\n",
    "unique_games.nlargest(5,[\"total_sales\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vrJdWVF-fHJe"
   },
   "source": [
    "Let's recheck this with another method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "pyCPp2DPfLol",
    "outputId": "e0d52ae0-4140-43f8-e7b3-cef94cd81ece"
   },
   "outputs": [],
   "source": [
    "df = clean_df_3[[\"platform\", \"total_sales\"]].groupby(\"platform\").sum().sort_values(by = \"total_sales\").reset_index()\n",
    "\n",
    "df.nlargest(5, \"total_sales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m3w9QsY0gbLA"
   },
   "source": [
    "Yep. Same guys at the top 5. Let's normalize the data somehow. We can zscore the data or min_max it between 0 and 1. \n",
    "\n",
    "Let's zscore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 681
    },
    "id": "_Vrzx_uahh28",
    "outputId": "ab269086-5bc7-4168-e5bb-4166ef161d29"
   },
   "outputs": [],
   "source": [
    "# Zscoring total_sales\n",
    "df['zscored_total_sales']=(df['total_sales']- df['total_sales'].mean()) / df['total_sales'].std()\n",
    "\n",
    "# To plot it, let's create a new column with two colors:\n",
    "df['color']=['black' if x<0 else 'green' for x in df['zscored_total_sales']]\n",
    "\n",
    "# Let's add a column plot it and see what can we learn:\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.hlines(y=df.platform,xmax=df.zscored_total_sales, xmin=0,color = df.color, alpha=0.8, linewidth=10)\n",
    "plt.title(\"Normalized sales per platform.\")\n",
    "plt.ylabel(\"Platforms\")\n",
    "plt.xlabel(\"Distribution of sales per platform\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpfYFvPPfXya"
   },
   "source": [
    "Our top 5 platforms are at the top of the green bars. The point that seperates the color is the mean. The green bars are total sales above the mean. The black bars beneath the mean.\n",
    "\n",
    "If we add to our top 5 list number 6 (platform PS), we can definetivly say that these 6 are the game industry showrunners on total, across the years.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1c4zkYDHkV84"
   },
   "source": [
    "**Find platforms that used to be popular but now have zero sales.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 603
    },
    "id": "gkMP25d7sXtA",
    "outputId": "b8e42e52-6a83-4fb0-87b4-9a20d6b0983d"
   },
   "outputs": [],
   "source": [
    "df=clean_df_3.groupby(['platform'])['year_of_release'].agg(['max']).sort_values(\"max\").head(15)\n",
    "\n",
    "print(\" The following list shows the last ~living year~ of 15 platforms. \\n\",\n",
    "\"Meaning that the latest game on this platform was published in that year.\")\n",
    "print(\" \")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13ijB8MerRoG"
   },
   "source": [
    "**How long does it generally take for new platforms to appear and old ones to fade?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ItVzYQ25koG4"
   },
   "source": [
    "Let's calculate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mqF3RozlHZHB",
    "outputId": "85b0c190-8f74-4508-c596-8b49239c7bb3"
   },
   "outputs": [],
   "source": [
    "# Creating new df with min max of all platforms. \n",
    "df=clean_df_3.groupby(['platform'])['year_of_release'].agg([\"min\", \"max\"]).reset_index()\n",
    "\n",
    "# Choosing only the platforms that were \"born\" on 2006 and later and \"died\" before 2016 (We don't want a living platforms in our calculation)\n",
    "df = df[df[\"min\"] >= 1990] \n",
    "\n",
    "# Saving the age as life_span\n",
    "df[\"life_span\"] = df[\"max\"] - df[\"min\"]\n",
    "\n",
    "print(\"The averaged mean/median lifespan of 1990  - 2016 born platforms is\", round((df.life_span.mean() + df.life_span.median()) / 2, 2), \"years.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G1QjtT4bTL1t"
   },
   "source": [
    "This 7.7 number might assist us in our further decisions - for example, we know how \"farther down the road\" of it's market life our platform is, since we know the avr year of platform's life. \n",
    "\n",
    "Another thing that this number might assist us with is filtering our data with 7.7 years. For example we might choose to look ONLY at the data from the platforms that are within this range of years (i.e. 2008+) and regard it a a logical subset, unlike subsets based on a more \"intuitive\" approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zPnYtjuQeL_"
   },
   "source": [
    "Let's see if there's a corr() between life_span and total sales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tlo8mdmxOQcw",
    "outputId": "c0554928-ec42-4a6b-879a-9b2025dfefb4"
   },
   "outputs": [],
   "source": [
    "df2=clean_df_3.groupby(['platform'])[\"total_sales\"].agg([\"min\", \"max\"]).reset_index()\n",
    "\n",
    "print(\"There's\", int(100*df2[\"max\"].corr(df[\"life_span\"])),\"% correlation between the life_span of the platform and its total revenue.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P88giPctYOcF"
   },
   "source": [
    "Well, no surprise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQvOkP9GisOM"
   },
   "source": [
    "### **Which platforms are leading in sales? Which ones are growing or shrinking? Select several potentially profitable platforms.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qnf4oza2hE-2"
   },
   "source": [
    "In order to answe this question let's put these life spans on a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 678
    },
    "id": "gma7ma4CkU6e",
    "outputId": "54dcba0d-8fd1-48b8-8d74-35938e6f5b92"
   },
   "outputs": [],
   "source": [
    "# Creating new df with games from 1980 and up\n",
    "df=clean_df_3[clean_df_3.year_of_release >= 1980]\n",
    "\n",
    "df=df.groupby(['platform','year_of_release'])['total_sales'].sum().reset_index().sort_values(by='year_of_release')\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "ax = sns.lineplot(data=df, x=\"year_of_release\", y=\"total_sales\",hue=\"platform\")\n",
    "ax.legend(bbox_to_anchor=(1.05,1.0),loc='best')\n",
    "plt.title(\"Platforms performance over the years.\")\n",
    "plt.ylabel(\"Games\")\n",
    "plt.xlabel(\"Years\")\n",
    "ax.set_facecolor('black')\n",
    "# ax.set_facecolor((1.0, 0.47, 0.42))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wqWWUdXejNaa"
   },
   "source": [
    "By just looking on the total period - from 1980 to 2016, we can definitely see the platforms \"born\" and \"die\". As we calculated previously the avr lifespan of a platform is 7.7 yeas. So let's subset the data from the last 8 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 536
    },
    "id": "LtMue7T3kVBg",
    "outputId": "337de322-7e09-46f2-f658-0584071c2005"
   },
   "outputs": [],
   "source": [
    "df=clean_df_3[clean_df_3.year_of_release >= 2013]\n",
    "\n",
    "df=df.groupby(['platform','year_of_release'])['total_sales'].sum().reset_index().sort_values(by='year_of_release')\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "ax = sns.lineplot(data=df, x=\"year_of_release\", y=\"total_sales\",hue=\"platform\")\n",
    "ax.legend(bbox_to_anchor=(1.05,1.0),loc='best')\n",
    "plt.title(\"Platforms performance over the years.\")\n",
    "plt.ylabel(\"Games\")\n",
    "plt.xlabel(\"Years\")\n",
    "ax.set_facecolor('black')\n",
    "# ax.set_facecolor((1.0, 0.47, 0.42))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQfRHdfgkPxk"
   },
   "source": [
    "**To the degree that the numbers for the year 2016 are final**, we can not ignore the overall **downtrend** in the sales, not just in the revenues of the top sellers, **but the game industry as a whole**. \n",
    "\n",
    "This downtrend might be explained by the fact that the users shift toward ONLINE and MOBILE app games, that are platform \"free\". In addition, in the last years, new trends have emerged  that did not exist previously, like  games on social mediaand so on.\n",
    "\n",
    "Back to the question: the \"profitiability\" of a platform **from our data** can only be calculated to the degree that the platform has sales... But sales, as we know, doesn't mean revenues. In addition, such \"profitability\" says little about the overall position of the platform on the market. As clearly seen in the graph in 2016 all platforms UNDERPERFORM their previous TWO years. A clear indication of industry downtrend (if measured by in total sales, given our data for 2016 is complete).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ePSa6jS5aM3F"
   },
   "source": [
    "Let's see this on a heat map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 753
    },
    "id": "kMvk5Y8sqEwP",
    "outputId": "d905dd54-40b5-4ed0-ffaa-1bb4da3e6694"
   },
   "outputs": [],
   "source": [
    "relevant_years=clean_df_3[clean_df_3.year_of_release>=2013]\n",
    "relevant_years\n",
    "\n",
    "df=pd.pivot_table(relevant_years, index='year_of_release',columns='platform',values='total_sales',aggfunc='sum',fill_value=0)\n",
    "trends = (df-df.shift(+1)).T\n",
    "\n",
    "\n",
    "plt.figure(figsize=(13,9))\n",
    "sns.heatmap(trends, cmap='RdBu_r')\n",
    "plt.title(\"Heatmap of platforms revenues\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wUGNPOXu2HN"
   },
   "source": [
    "The heatmap above clearly demonstrates the \"relevance\" of a platform. We want to choose the most profitable platforms in the recent years - on the graph these platforms have the most brownish-red colors. We identified 2 platforms that met this criteria:  XOne and PS4. Both are in the downtrend (as noted previously) and their total sales are shrinking but (since we are pushed to the wall and must choose) these are our top 2 platforms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6awCY7Ezk8j"
   },
   "source": [
    "### **Build a box plot for the global sales of each game, broken down by platform. Are the differences in sales significant? What about average sales on various platforms? Describe your findings.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w9SgfKhgkVGo"
   },
   "outputs": [],
   "source": [
    "# Let's take only the relevant period of years.\n",
    "data_new = clean_df_3[clean_df_3.year_of_release >= 2013]\n",
    "\n",
    "# and group it by platform and name, then summing the total sales\n",
    "grouped = data_new.groupby(['platform','name'])['total_sales'].sum().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 825
    },
    "id": "mIVkqUwp0-1T",
    "outputId": "aa8dd937-41bc-44bc-e624-fbfb7d699bfc"
   },
   "outputs": [],
   "source": [
    "# let's plot it.\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(13,10))\n",
    "sns.boxplot(x='platform',y='total_sales',data=grouped, showfliers = False)\n",
    "plt.title(\"Boxplot of global sales of each game/per platform, not incl outliers \")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6kY_Pb9hct8f"
   },
   "source": [
    "The box plot above demonstrates the historical state of the industry (bt 2013-2016). What we can learn is the overall distribution of sales on the platforms. Some platforms are \"dying\" with diminishing sales while others still demonstrate very strong performance with very high medians of sales.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ftS1sbnXdhep",
    "outputId": "fae959b8-30e4-4df9-c26e-fc0898d73036"
   },
   "outputs": [],
   "source": [
    "print(\"The avr total sales across all relevant platforms is :\", round(grouped.total_sales.mean(),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cpt_Wupp4139"
   },
   "source": [
    "#### **Take a look at how user and professional reviews affect sales for one popular platform (you choose). Build a scatter plot and calculate the correlation between reviews and sales. Draw conclusions.**\n",
    "#### **Keeping your conclusions in mind, compare the sales of the same games on other platforms**.\n",
    "\n",
    "- build a function and iterate over it \n",
    "\n",
    "To answer this question let's first clean our data a little:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YgDUSkN88GzF",
    "outputId": "9a03d85a-bd6a-4a66-aa67-0a3fa96806da"
   },
   "outputs": [],
   "source": [
    "clean_df_4 = data_new[(data_new.user_score.notna()) & (data_new.user_score != \"tbd\") & (data_new.critic_score.notna()) ]\n",
    "clean_df_4.user_score = clean_df_4.user_score.astype(float)\n",
    "clean_df_4.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3IBvtDAepLf"
   },
   "source": [
    "Now let's build a func to do the hardlifting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8oLj5Rpl5BsC",
    "outputId": "67f7cce6-e9c9-4afa-cf24-745842fb6fe3"
   },
   "outputs": [],
   "source": [
    "# Function that calculates the corr btw scores and total sales. \n",
    "\n",
    "def score_effect(platform,score_type):\n",
    "    data=clean_df_4[(clean_df_4.platform == platform) & (clean_df_4[score_type]).notna()][['total_sales', score_type]]\n",
    "    correlation = data[score_type].corr(data.total_sales)\n",
    "    return correlation\n",
    "\n",
    "plats = clean_df_4.platform.unique().tolist()\n",
    "types = [\"user_score\", \"critic_score\"]\n",
    "corr_list = []\n",
    "\n",
    "for p in plats:\n",
    "  for t in types:\n",
    "    corr_list.append([p, t, round(score_effect(p,t), 2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z1DKPF2qeyqU"
   },
   "source": [
    "Let's display our findings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 865
    },
    "id": "6qHcKtyU5BvX",
    "outputId": "a69bc87d-a88a-4288-cb14-c75448ea4bac"
   },
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(data = corr_list, columns = [\"platform\", \"score_type\", \"corr\"])\n",
    "new_df.sort_values(\"corr\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mKSxlXs3MYa-"
   },
   "source": [
    "Our new df shows that critic scores, on most platforms, have higher corr with total sales than the user_scores. Probably because they review the games before they are distributed. Let's see this on a graph for platform : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 962
    },
    "id": "vp6E1aVO5Bxi",
    "outputId": "ee312690-09e6-4ec9-8205-15c442ac7fc6"
   },
   "outputs": [],
   "source": [
    "game = clean_df_4.query('platform == \"PS4\"')\n",
    "\n",
    "sales_ratings_scatter = game.pivot_table(index =\"total_sales\", values = [\"critic_score\", \"user_score\"])\n",
    "\n",
    "pd.plotting.scatter_matrix(sales_ratings_scatter, figsize = (8,8))\n",
    "\n",
    "plt.title(\"Influence of critics on sales in PS4\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "game.corr()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I1FZAHGyhWqA"
   },
   "source": [
    "The table graph and the table demonstrate a clear corr btw critics and sales. The highier the critic's score - the highier the score. This is hardly a linear correlation but nevertheless it exists and should not be ignored. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "teGwVkLMjIgg"
   },
   "source": [
    "**Take a look at the general distribution of games by genre. What can we say about the most profitable genres? Can you generalize about genres with high and low sales?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 681
    },
    "id": "Bp8dbXColkDx",
    "outputId": "0a5fe58a-72e5-4b2d-ce48-c7e740607f7b"
   },
   "outputs": [],
   "source": [
    "# Let's take only the relevant period of years.\n",
    "data_new = clean_df_3[clean_df_3.year_of_release >= 2008]\n",
    "\n",
    "# and group it by platform and name, then summing the total sales\n",
    "grouped = data_new.groupby(['genre'])['total_sales'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(13,8))\n",
    "sns.boxplot(x='genre',y='total_sales',data=grouped)\n",
    "plt.title(\"Total sales by genre, not incl outliers \")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lsyVnkMoo0Ja"
   },
   "source": [
    "Table above clearly demonstrates that on mean of total sales across all platform the winning genre is \"shooter\" and \"platformers\". Adventure games seems to have the lowest total sales, followed by a puzzle and strategy games. Seems like people want to be entertained and not develop their brains..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "udZTA1LdPnxX"
   },
   "source": [
    "### Step 4. Create a user profile for each region\n",
    "For each region (NA, EU, JP), determine:\n",
    "\n",
    "The top five platforms. Describe variations in their market shares from region to region.\n",
    "\n",
    "The top five genres. \n",
    "\n",
    "Explain the difference.\n",
    "\n",
    "Do ESRB ratings affect sales in individual regions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OqBSv1JFPwTC",
    "outputId": "ec3966e4-aac2-4804-c67e-30941ab22763"
   },
   "outputs": [],
   "source": [
    "# Let's calculate the top selling platforms in eu, jp, na regions:\n",
    "\n",
    "NA=clean_df_4.groupby(['platform'])['na_sales'].mean().reset_index().sort_values(by='na_sales',ascending=False).head()\n",
    "print(\"The Top platforms in NA region are:\", NA.platform.tolist()) \n",
    "\n",
    "JP=clean_df_4.groupby(['platform'])['jp_sales'].mean().reset_index().sort_values(by='jp_sales',ascending=False).head()\n",
    "print(\"The Top platforms in JP region are:\", JP.platform.tolist()) \n",
    "\n",
    "EU=clean_df_4.groupby(['platform'])['eu_sales'].mean().reset_index().sort_values(by='eu_sales',ascending=False).head()\n",
    "print(\"The Top platforms in EU region are:\", EU.platform.tolist()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3FcDxXU9H4x-",
    "outputId": "12057efa-9cde-46ce-9011-05704e978ccc"
   },
   "outputs": [],
   "source": [
    "NA.platform.value_counts().plot.pie(y='type', figsize=(6, 6), autopct='%1.1f%%',title = \"Best selling platforms in NA\")\n",
    "plt.show()\n",
    "\n",
    "EU.platform.value_counts().plot.pie(y='type', figsize=(6, 6), autopct='%1.1f%%',title = \"Best selling platforms in EU\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "JP.platform.value_counts().plot.pie(y='type', figsize=(6, 6), autopct='%1.1f%%',title = \"Best selling platforms in JP\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3UrvsSsmPwao",
    "outputId": "36ce1e3b-f662-4fe4-b3c2-eb77cdc77bc1"
   },
   "outputs": [],
   "source": [
    "# Let's find the top five genres in our regions:\n",
    "\n",
    "NA=clean_df_4.groupby(['genre'])['na_sales'].mean().reset_index().sort_values(by='genre',ascending=False).head()\n",
    "print(\"The Top genres in NA region are:\", NA.genre.tolist()) \n",
    "\n",
    "JP=clean_df_4.groupby(['genre'])['jp_sales'].mean().reset_index().sort_values(by='genre',ascending=False).head()\n",
    "print(\"The Top genres in JP region are:\", JP.genre.tolist()) \n",
    "\n",
    "EU=clean_df_4.groupby(['genre'])['eu_sales'].mean().reset_index().sort_values(by='genre',ascending=False).head()\n",
    "print(\"The Top genres in EU region are:\", EU.genre.tolist()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ko0EDE2kqJI8"
   },
   "source": [
    "Seems like people change but not in nature. The same exact genres, in the same exact order..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IjecqGI7Xu2_"
   },
   "source": [
    "Let's check the corr between the genres and the sales in these regions... In order to do this let's asign numbers to the genres and use them insted of \"genre\" table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PQlz7bX6Pwfm",
    "outputId": "bb4c5779-598d-48d7-bff2-7d4cfd3d1952"
   },
   "outputs": [],
   "source": [
    "\n",
    "NA=clean_df_4.groupby(['genre'])['na_sales'].mean().reset_index().sort_values(by='genre',ascending=False).head().reset_index()\n",
    "NA[\"int_label\"] = NA.index + 1\n",
    "print(\"The genre corr in NA region is:\", round(NA.int_label.corr(NA.na_sales),2))\n",
    "\n",
    "JP=clean_df_4.groupby(['genre'])['jp_sales'].mean().reset_index().sort_values(by='genre',ascending=False).head().reset_index()\n",
    "JP[\"int_label\"] = JP.index + 1\n",
    "print(\"The genre corr in JP region is:\", round(JP.int_label.corr(JP.jp_sales),2)) \n",
    "\n",
    "EU=clean_df_4.groupby(['genre'])['eu_sales'].mean().reset_index().sort_values(by='genre',ascending=False).head().reset_index()\n",
    "EU[\"int_label\"] = EU.index + 1\n",
    "print(\"The genre corr in EU region is:\", round(EU.int_label.corr(EU.eu_sales),2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yhgdNFJYXbot"
   },
   "source": [
    "Seems like in JP and EU, there is very significant correlation between the genre and the sales. \n",
    "\n",
    "Let's see if ratings affect the sales in these regions. We are doing the same exact trick with the obj column of rating: we are asigning it a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vU6c_ZPKX0YT",
    "outputId": "ee7706cf-d27b-41ef-ec68-6332ca83ca79"
   },
   "outputs": [],
   "source": [
    "NA=clean_df_4.groupby(['rating'])['na_sales'].mean().reset_index().sort_values(by='rating',ascending=False).head().reset_index()\n",
    "NA[\"int_label\"] = NA.index + 1\n",
    "print(\"The rating/sales corr in NA region is:\", round(NA.int_label.corr(NA.na_sales),2))\n",
    "\n",
    "JP=clean_df_4.groupby(['rating'])['jp_sales'].mean().reset_index().sort_values(by='rating',ascending=False).head().reset_index()\n",
    "JP[\"int_label\"] = JP.index + 1\n",
    "print(\"The rating/sales corr in JP region is:\", round(JP.int_label.corr(JP.jp_sales),2)) \n",
    "\n",
    "EU=clean_df_4.groupby(['rating'])['eu_sales'].mean().reset_index().sort_values(by='rating',ascending=False).head().reset_index()\n",
    "EU[\"int_label\"] = EU.index + 1\n",
    "print(\"The rating/sales corr in EU region is:\", round(EU.int_label.corr(EU.eu_sales),2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "reww-aIEKV4V"
   },
   "source": [
    "The corr of ratings and sales in EU is the highest -  56%!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ifBAkPEfswIR",
    "outputId": "1db4fd94-5de1-4eea-8673-37d0d0294aca"
   },
   "outputs": [],
   "source": [
    "for region in [\"na_sales\", \"eu_sales\", \"jp_sales\"]:\n",
    "  mean=clean_df_4.groupby(['rating'])[region].mean().reset_index().sort_values(by=region,ascending=False).reset_index().head(5)\n",
    "  total=clean_df_4.groupby(['rating'])[region].sum().reset_index().sort_values(by=region,ascending=False).reset_index().head(5)\n",
    "  winning_ratings = [x for x in mean.rating.to_list() if x in total.rating.to_list()]\n",
    "  print(region, \"best selling ratings :\", winning_ratings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hjvV_wLyYqME"
   },
   "source": [
    "Our analysis shows that na, eu and jp regions have identical group of top 5 (4 actually, NA is not a rating) ratings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGckkFiPjqle"
   },
   "source": [
    "### Step 5. Test the following hypotheses:\n",
    "\n",
    "#### H*o*, null: Average user ratings of the Xbox One and PC platforms are the same.\n",
    "\n",
    "#### H*a*, null: Average user ratings of the Xbox One and PC platforms are not the same.\n",
    "\n",
    "##### Significance level: alpha = 0.08\n",
    "\n",
    "##### n = 120 samples from each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J9s6MlX-jvb1",
    "outputId": "b76583ef-61df-49cc-9aac-816d660011a3"
   },
   "outputs": [],
   "source": [
    "from scipy import stats as st\n",
    "\n",
    "pc = clean_df_4.query(\"platform == 'PC'\")\n",
    "xone =  clean_df_4.query(\"platform == 'XOne'\")\n",
    "\n",
    "# Let's set alpha level\n",
    "alpha = 0.08\n",
    "\n",
    "results = st.ttest_ind(pc[\"user_score\"].sample(n=120), xone[\"user_score\"].sample(n=120),  equal_var = False)\n",
    "\n",
    "if results.pvalue < alpha:\n",
    "  print(\"We reject the null hypothesis, because:\")\n",
    "else:\n",
    "  print(\"We can't reject the null hypothesis, because:\")\n",
    "\n",
    "print(\"Our pvalue is\", round(results.pvalue,4))\n",
    "print(\"PC user_score mean is\", pc.user_score.mean())\n",
    "print(\"Xbox_one user_score mean is\", xone.user_score.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHl8zN-zsf58"
   },
   "source": [
    "My Comment. v. 1 : DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6py2tzgIscfE"
   },
   "source": [
    "#### Hypotheses 2 \n",
    "\n",
    "#### H*a*, alternative: Average user ratings for the Action and Sports genres are different.\n",
    "\n",
    "#### H*o*, alternative: Average user ratings for the Action and Sports genres are the same.\n",
    "\n",
    "This means that our null H is that the ratings for Action and Sports genres are the same. \n",
    "\n",
    "Significance level: alpha = 0.08\n",
    "\n",
    "n = 150 samples from each group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MAFWMrs0nGEp",
    "outputId": "36f0c727-b57d-42b3-f4d3-5769826b2956"
   },
   "outputs": [],
   "source": [
    "from scipy import stats as st\n",
    "\n",
    "action = clean_df_4.query(\"genre == 'Action'\")\n",
    "sports =  clean_df_4.query(\"genre == 'Sports'\")\n",
    "\n",
    "# Let's set alpha level\n",
    "alpha = 0.08\n",
    "\n",
    "results = st.ttest_ind(pc[\"user_score\"].sample(n=100), xone[\"user_score\"].sample(n=100),  equal_var = False)\n",
    "\n",
    "if results.pvalue < alpha:\n",
    "  print(\"We reject the null hypothesis, because:\")\n",
    "else:\n",
    "  print(\"We can't reject the null hypothesis, because:\")\n",
    "\n",
    "print(\"Our pvalue is\", round(results.pvalue,2))\n",
    "print(\"Sports genre user_score mean is\", sports.user_score.mean())\n",
    "print(\"Action genre user_score mean is\", action.user_score.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "drPqb-UGtZFt"
   },
   "source": [
    "We defined our alpha on 8%, (5% to 8% are the most commonly used values for alpha for rejecting the null hypotheses.) Running the experement several times we can state the following:\n",
    "\n",
    "We can't regect the null H1 that the average user ratings of the Xbox One and PC platforms are the same because their pvalue is 25% (our alpha is 8%)\n",
    "\n",
    "We cannot reject the null H2 hypotheses that the average user ratings for the Action and Sports genres are the same because our pvalue is 17%. Therefore we reject our original, alternative hypotheses. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDhxyddgyLAg"
   },
   "source": [
    "Conclution:\n",
    "\n",
    "We started our analysis by getting ourselves familiar wt the dataset. By calling a few info functions we noticed object columns that might cause us problems later on. Therefore we:\n",
    "\n",
    "* lowercased the column names,\n",
    "* Restored  1910 missing ratings based on the names of the games and year of release.\n",
    "* Explained the distribution of tbds in the user score column.\n",
    "* Restored 175 instances of missing year_of_release using the names of the games. \n",
    "* Calculated total sales column\n",
    "* Analyzed the data by answering the questions in the taskand checking the hypotheseses proposed. \n",
    "\n",
    "Our overall conclution might be summerized in the following:\n",
    "\n",
    "* Importance of clearly defined criteria for data gathering: parameters must be relevant (in our example 50% of the data was too old).\n",
    "* The data must be complete (we proposed our suspicion that the data for 2016 sales is not complete.)\n",
    "* Game store must pay very close attention to critics. Their ratings tend to boost the sales.\n",
    "* Game store should be familiar with the top 5 genres. Yet, with regards to the genre, it is less off importance in which region the store is located, since the top 5 genres tend to be the same in na, jp and eu.    \n",
    "* Given that our dataset is complete, most of the platforms are either \"dead\" or dying. There seems to be a new trends on the market that are not reflected in our dataset, like \"platform free\" mobile games (apps) and online games. \n",
    "* The avr lifespan of a platform is 7.7 years. This means that buying stocks of a new game of a platform that is 8 years old, might be very risky.  \n",
    "* All platforms are not born equal. Some do better than others. With that said, the market is constantly changing and moving. Uptrends of yesterdays are downtrends of tommorow. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'><b><u> Reviewer Comment. v. 2  </u></b></font>\n",
    "\n",
    "<div class=\"alert alert-success\" >\n",
    "    \n",
    "**Success:**  The overall conclusion is clear👍\n",
    "\n",
    "To sum up: an extremely thorough analysis, detailed conclusions and neat style. \n",
    "\n",
    "Thank you for good job! \n",
    "\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1281,
    "start_time": "2022-02-15T17:15:09.619Z"
   },
   {
    "duration": 167,
    "start_time": "2022-02-15T17:15:12.055Z"
   },
   {
    "duration": 556,
    "start_time": "2022-02-15T17:15:14.305Z"
   },
   {
    "duration": 13,
    "start_time": "2022-02-15T17:15:19.126Z"
   },
   {
    "duration": 483,
    "start_time": "2022-02-15T17:15:22.422Z"
   },
   {
    "duration": 10,
    "start_time": "2022-02-15T17:15:41.358Z"
   },
   {
    "duration": 292,
    "start_time": "2022-02-15T17:15:44.068Z"
   },
   {
    "duration": 37,
    "start_time": "2022-02-15T17:16:53.149Z"
   },
   {
    "duration": 42,
    "start_time": "2022-02-15T17:16:55.077Z"
   },
   {
    "duration": 16,
    "start_time": "2022-02-15T17:16:59.632Z"
   },
   {
    "duration": 10,
    "start_time": "2022-02-15T17:17:02.013Z"
   },
   {
    "duration": 231,
    "start_time": "2022-02-15T17:17:05.309Z"
   },
   {
    "duration": 6,
    "start_time": "2022-02-15T17:17:10.540Z"
   },
   {
    "duration": 6,
    "start_time": "2022-02-15T17:17:13.499Z"
   },
   {
    "duration": 6,
    "start_time": "2022-02-15T17:17:15.259Z"
   },
   {
    "duration": 36,
    "start_time": "2022-02-15T17:17:20.092Z"
   },
   {
    "duration": 15,
    "start_time": "2022-02-15T17:17:28.549Z"
   },
   {
    "duration": 10,
    "start_time": "2022-02-15T17:17:32.744Z"
   },
   {
    "duration": 32,
    "start_time": "2022-02-15T17:17:35.524Z"
   },
   {
    "duration": 12,
    "start_time": "2022-02-15T17:17:37.588Z"
   },
   {
    "duration": 26,
    "start_time": "2022-02-15T17:17:42.787Z"
   },
   {
    "duration": 15,
    "start_time": "2022-02-15T17:17:59.763Z"
   },
   {
    "duration": 4,
    "start_time": "2022-02-15T17:19:19.490Z"
   },
   {
    "duration": 417,
    "start_time": "2022-02-15T17:19:26.873Z"
   },
   {
    "duration": 41,
    "start_time": "2022-02-15T17:19:37.619Z"
   },
   {
    "duration": 37,
    "start_time": "2022-02-15T17:19:45.770Z"
   },
   {
    "duration": 43,
    "start_time": "2022-02-15T17:19:47.385Z"
   },
   {
    "duration": 17,
    "start_time": "2022-02-15T17:19:53.425Z"
   },
   {
    "duration": 8,
    "start_time": "2022-02-15T17:19:57.650Z"
   },
   {
    "duration": 550,
    "start_time": "2022-02-15T17:20:08.121Z"
   },
   {
    "duration": 228,
    "start_time": "2022-02-15T17:20:15.938Z"
   },
   {
    "duration": 216,
    "start_time": "2022-02-15T17:20:19.576Z"
   },
   {
    "duration": 6,
    "start_time": "2022-02-15T17:20:22.447Z"
   },
   {
    "duration": 7,
    "start_time": "2022-02-15T17:20:25.719Z"
   },
   {
    "duration": 14,
    "start_time": "2022-02-15T17:20:30.848Z"
   },
   {
    "duration": 10,
    "start_time": "2022-02-15T17:21:16.166Z"
   },
   {
    "duration": 4,
    "start_time": "2022-02-15T17:21:40.079Z"
   },
   {
    "duration": 40,
    "start_time": "2022-02-15T17:21:40.614Z"
   },
   {
    "duration": 45,
    "start_time": "2022-02-15T17:21:42.799Z"
   },
   {
    "duration": 14,
    "start_time": "2022-02-15T17:21:49.952Z"
   },
   {
    "duration": 13,
    "start_time": "2022-02-15T17:21:56.702Z"
   },
   {
    "duration": 233,
    "start_time": "2022-02-15T17:22:10.406Z"
   },
   {
    "duration": 15,
    "start_time": "2022-02-15T17:22:23.004Z"
   },
   {
    "duration": 92,
    "start_time": "2022-02-15T17:26:11.400Z"
   },
   {
    "duration": 87,
    "start_time": "2022-02-15T17:26:35.448Z"
   },
   {
    "duration": 318,
    "start_time": "2022-02-15T17:27:12.039Z"
   },
   {
    "duration": 323,
    "start_time": "2022-02-15T17:27:42.797Z"
   },
   {
    "duration": 53,
    "start_time": "2022-02-15T17:27:54.517Z"
   },
   {
    "duration": 253,
    "start_time": "2022-02-15T17:29:39.986Z"
   },
   {
    "duration": 12,
    "start_time": "2022-02-15T17:30:05.218Z"
   },
   {
    "duration": 51,
    "start_time": "2022-02-15T17:30:23.314Z"
   },
   {
    "duration": 36,
    "start_time": "2022-02-15T17:31:57.778Z"
   },
   {
    "duration": 42,
    "start_time": "2022-02-15T17:32:17.673Z"
   },
   {
    "duration": 14,
    "start_time": "2022-02-15T17:32:27.262Z"
   },
   {
    "duration": 9,
    "start_time": "2022-02-15T17:32:45.223Z"
   },
   {
    "duration": 49,
    "start_time": "2022-02-15T17:32:58.193Z"
   },
   {
    "duration": 323,
    "start_time": "2022-02-15T17:34:04.270Z"
   },
   {
    "duration": 45,
    "start_time": "2022-02-15T17:34:12.111Z"
   },
   {
    "duration": 45,
    "start_time": "2022-02-15T17:34:23.630Z"
   },
   {
    "duration": 38,
    "start_time": "2022-02-15T17:34:27.067Z"
   },
   {
    "duration": 15,
    "start_time": "2022-02-15T17:34:32.244Z"
   },
   {
    "duration": 8,
    "start_time": "2022-02-15T17:34:35.251Z"
   },
   {
    "duration": 214,
    "start_time": "2022-02-15T17:34:44.404Z"
   },
   {
    "duration": 226,
    "start_time": "2022-02-15T17:35:01.268Z"
   },
   {
    "duration": 226,
    "start_time": "2022-02-15T17:35:17.659Z"
   },
   {
    "duration": 217,
    "start_time": "2022-02-15T17:35:22.324Z"
   },
   {
    "duration": 213,
    "start_time": "2022-02-15T17:35:28.815Z"
   },
   {
    "duration": 8,
    "start_time": "2022-02-15T17:36:19.197Z"
   },
   {
    "duration": 6,
    "start_time": "2022-02-15T17:36:26.201Z"
   },
   {
    "duration": 6,
    "start_time": "2022-02-15T17:37:39.048Z"
   },
   {
    "duration": 6,
    "start_time": "2022-02-15T17:37:44.146Z"
   },
   {
    "duration": 5,
    "start_time": "2022-02-15T17:38:09.107Z"
   },
   {
    "duration": 5,
    "start_time": "2022-02-15T17:38:15.471Z"
   },
   {
    "duration": 32,
    "start_time": "2022-02-15T17:38:26.029Z"
   },
   {
    "duration": 13,
    "start_time": "2022-02-15T17:38:43.703Z"
   },
   {
    "duration": 11,
    "start_time": "2022-02-15T17:38:56.671Z"
   },
   {
    "duration": 32,
    "start_time": "2022-02-15T17:39:01.679Z"
   },
   {
    "duration": 22,
    "start_time": "2022-02-15T17:39:18.352Z"
   },
   {
    "duration": 12,
    "start_time": "2022-02-15T17:39:37.727Z"
   },
   {
    "duration": 38,
    "start_time": "2022-02-15T17:39:43.457Z"
   },
   {
    "duration": 26,
    "start_time": "2022-02-15T17:39:58.278Z"
   },
   {
    "duration": 32,
    "start_time": "2022-02-15T17:40:21.198Z"
   },
   {
    "duration": 11,
    "start_time": "2022-02-15T17:40:33.727Z"
   },
   {
    "duration": 12,
    "start_time": "2022-02-15T17:40:57.767Z"
   },
   {
    "duration": 30,
    "start_time": "2022-02-15T17:41:13.500Z"
   },
   {
    "duration": 15,
    "start_time": "2022-02-15T17:42:09.967Z"
   },
   {
    "duration": 124,
    "start_time": "2022-02-24T03:52:50.535Z"
   },
   {
    "duration": 109,
    "start_time": "2022-02-24T04:14:19.576Z"
   },
   {
    "duration": 1504,
    "start_time": "2022-02-24T13:50:29.467Z"
   },
   {
    "duration": 58,
    "start_time": "2022-02-24T13:50:31.747Z"
   },
   {
    "duration": 26,
    "start_time": "2022-02-24T13:50:43.067Z"
   },
   {
    "duration": 452,
    "start_time": "2022-02-24T13:50:44.647Z"
   },
   {
    "duration": 18,
    "start_time": "2022-02-24T13:50:51.687Z"
   },
   {
    "duration": 46,
    "start_time": "2022-02-24T13:50:55.046Z"
   },
   {
    "duration": 57,
    "start_time": "2022-02-24T13:50:56.648Z"
   },
   {
    "duration": 11,
    "start_time": "2022-02-24T13:50:59.155Z"
   },
   {
    "duration": 8,
    "start_time": "2022-02-24T13:51:00.834Z"
   },
   {
    "duration": 12,
    "start_time": "2022-02-24T13:51:02.510Z"
   },
   {
    "duration": 32,
    "start_time": "2022-02-24T13:51:03.811Z"
   },
   {
    "duration": 34,
    "start_time": "2022-02-24T13:51:07.738Z"
   },
   {
    "duration": 10,
    "start_time": "2022-02-24T13:51:43.643Z"
   },
   {
    "duration": 16,
    "start_time": "2022-02-24T13:51:44.655Z"
   },
   {
    "duration": 23,
    "start_time": "2022-02-24T13:51:45.475Z"
   },
   {
    "duration": 15129,
    "start_time": "2022-02-24T13:51:46.955Z"
   },
   {
    "duration": 7,
    "start_time": "2022-02-24T13:52:02.087Z"
   },
   {
    "duration": 57,
    "start_time": "2022-02-24T13:52:02.098Z"
   },
   {
    "duration": 602,
    "start_time": "2022-02-24T13:52:02.158Z"
   },
   {
    "duration": 6,
    "start_time": "2022-02-24T13:52:04.803Z"
   },
   {
    "duration": 12,
    "start_time": "2022-02-24T13:52:13.167Z"
   },
   {
    "duration": 30,
    "start_time": "2022-02-24T13:52:17.567Z"
   },
   {
    "duration": 23,
    "start_time": "2022-02-24T13:52:20.190Z"
   },
   {
    "duration": 13198,
    "start_time": "2022-02-24T13:52:21.935Z"
   },
   {
    "duration": 25,
    "start_time": "2022-02-24T13:52:35.136Z"
   },
   {
    "duration": 611,
    "start_time": "2022-02-24T13:52:35.164Z"
   },
   {
    "duration": 50,
    "start_time": "2022-02-24T13:52:35.778Z"
   },
   {
    "duration": 11,
    "start_time": "2022-02-24T13:52:40.887Z"
   },
   {
    "duration": 19,
    "start_time": "2022-02-24T13:52:43.943Z"
   },
   {
    "duration": 822,
    "start_time": "2022-02-24T13:52:47.427Z"
   },
   {
    "duration": 13987,
    "start_time": "2022-02-24T13:54:00.776Z"
   },
   {
    "duration": 283,
    "start_time": "2022-02-24T13:54:14.486Z"
   },
   {
    "duration": 281,
    "start_time": "2022-02-24T13:54:14.490Z"
   },
   {
    "duration": 253,
    "start_time": "2022-02-24T13:54:14.520Z"
   },
   {
    "duration": 251,
    "start_time": "2022-02-24T13:54:14.524Z"
   },
   {
    "duration": 249,
    "start_time": "2022-02-24T13:54:14.527Z"
   },
   {
    "duration": 246,
    "start_time": "2022-02-24T13:54:14.532Z"
   },
   {
    "duration": 244,
    "start_time": "2022-02-24T13:54:14.535Z"
   },
   {
    "duration": 242,
    "start_time": "2022-02-24T13:54:14.538Z"
   },
   {
    "duration": 241,
    "start_time": "2022-02-24T13:54:14.541Z"
   },
   {
    "duration": 238,
    "start_time": "2022-02-24T13:54:14.545Z"
   },
   {
    "duration": 233,
    "start_time": "2022-02-24T13:54:14.551Z"
   },
   {
    "duration": 232,
    "start_time": "2022-02-24T13:54:14.554Z"
   },
   {
    "duration": 231,
    "start_time": "2022-02-24T13:54:14.557Z"
   },
   {
    "duration": 229,
    "start_time": "2022-02-24T13:54:14.560Z"
   },
   {
    "duration": 227,
    "start_time": "2022-02-24T13:54:14.563Z"
   },
   {
    "duration": 224,
    "start_time": "2022-02-24T13:54:14.567Z"
   },
   {
    "duration": 223,
    "start_time": "2022-02-24T13:54:14.570Z"
   },
   {
    "duration": 215,
    "start_time": "2022-02-24T13:54:14.579Z"
   },
   {
    "duration": 213,
    "start_time": "2022-02-24T13:54:14.582Z"
   },
   {
    "duration": 210,
    "start_time": "2022-02-24T13:54:14.586Z"
   },
   {
    "duration": 187,
    "start_time": "2022-02-24T13:54:14.611Z"
   },
   {
    "duration": 183,
    "start_time": "2022-02-24T13:54:14.616Z"
   },
   {
    "duration": 182,
    "start_time": "2022-02-24T13:54:14.619Z"
   },
   {
    "duration": 180,
    "start_time": "2022-02-24T13:54:14.622Z"
   },
   {
    "duration": 176,
    "start_time": "2022-02-24T13:54:14.627Z"
   },
   {
    "duration": 172,
    "start_time": "2022-02-24T13:54:14.633Z"
   },
   {
    "duration": 190,
    "start_time": "2022-02-24T13:54:14.637Z"
   },
   {
    "duration": 189,
    "start_time": "2022-02-24T13:54:14.640Z"
   },
   {
    "duration": 188,
    "start_time": "2022-02-24T13:54:14.643Z"
   },
   {
    "duration": 186,
    "start_time": "2022-02-24T13:54:14.647Z"
   },
   {
    "duration": 186,
    "start_time": "2022-02-24T13:54:14.650Z"
   },
   {
    "duration": 129,
    "start_time": "2022-02-24T13:54:14.709Z"
   },
   {
    "duration": 107,
    "start_time": "2022-02-24T13:54:14.733Z"
   },
   {
    "duration": 106,
    "start_time": "2022-02-24T13:54:14.736Z"
   },
   {
    "duration": 104,
    "start_time": "2022-02-24T13:54:14.739Z"
   },
   {
    "duration": 74,
    "start_time": "2022-02-24T13:54:14.771Z"
   },
   {
    "duration": 69,
    "start_time": "2022-02-24T13:54:14.778Z"
   },
   {
    "duration": 66,
    "start_time": "2022-02-24T13:54:14.782Z"
   },
   {
    "duration": 55,
    "start_time": "2022-02-24T13:54:14.795Z"
   },
   {
    "duration": 45,
    "start_time": "2022-02-24T13:54:14.807Z"
   },
   {
    "duration": 33,
    "start_time": "2022-02-24T13:54:14.820Z"
   },
   {
    "duration": 31,
    "start_time": "2022-02-24T13:54:14.823Z"
   },
   {
    "duration": 20,
    "start_time": "2022-02-24T13:54:14.836Z"
   },
   {
    "duration": 11,
    "start_time": "2022-02-24T13:54:14.847Z"
   },
   {
    "duration": 9,
    "start_time": "2022-02-24T13:54:14.850Z"
   },
   {
    "duration": -9,
    "start_time": "2022-02-24T13:54:14.870Z"
   },
   {
    "duration": -52,
    "start_time": "2022-02-24T13:54:14.914Z"
   },
   {
    "duration": 7,
    "start_time": "2022-02-24T13:54:14.918Z"
   },
   {
    "duration": 6,
    "start_time": "2022-02-24T13:54:14.921Z"
   },
   {
    "duration": 5,
    "start_time": "2022-02-24T13:54:14.924Z"
   },
   {
    "duration": 3,
    "start_time": "2022-02-24T13:54:14.927Z"
   },
   {
    "duration": 2,
    "start_time": "2022-02-24T13:54:14.930Z"
   },
   {
    "duration": 1,
    "start_time": "2022-02-24T13:54:14.933Z"
   },
   {
    "duration": -1,
    "start_time": "2022-02-24T13:54:14.936Z"
   },
   {
    "duration": -2,
    "start_time": "2022-02-24T13:54:14.939Z"
   },
   {
    "duration": 3427,
    "start_time": "2022-02-24T13:54:27.920Z"
   },
   {
    "duration": 5031,
    "start_time": "2022-02-24T13:54:38.819Z"
   },
   {
    "duration": 56,
    "start_time": "2022-02-24T13:54:43.853Z"
   },
   {
    "duration": 31,
    "start_time": "2022-02-24T13:54:43.913Z"
   },
   {
    "duration": 921,
    "start_time": "2022-02-24T13:54:43.947Z"
   },
   {
    "duration": 45,
    "start_time": "2022-02-24T13:54:44.870Z"
   },
   {
    "duration": 48,
    "start_time": "2022-02-24T13:54:44.917Z"
   },
   {
    "duration": 9,
    "start_time": "2022-02-24T13:54:44.968Z"
   },
   {
    "duration": 9,
    "start_time": "2022-02-24T13:54:44.981Z"
   },
   {
    "duration": 13,
    "start_time": "2022-02-24T13:54:45.028Z"
   },
   {
    "duration": 53,
    "start_time": "2022-02-24T13:54:45.044Z"
   },
   {
    "duration": 44,
    "start_time": "2022-02-24T13:54:45.099Z"
   },
   {
    "duration": 9,
    "start_time": "2022-02-24T13:54:45.146Z"
   },
   {
    "duration": 26,
    "start_time": "2022-02-24T13:54:45.157Z"
   },
   {
    "duration": 56,
    "start_time": "2022-02-24T13:54:45.186Z"
   },
   {
    "duration": 9629,
    "start_time": "2022-02-24T13:54:45.245Z"
   },
   {
    "duration": 6,
    "start_time": "2022-02-24T13:54:54.876Z"
   },
   {
    "duration": 43,
    "start_time": "2022-02-24T13:54:54.885Z"
   },
   {
    "duration": 401,
    "start_time": "2022-02-24T13:54:54.930Z"
   },
   {
    "duration": 6,
    "start_time": "2022-02-24T13:54:55.333Z"
   },
   {
    "duration": 28,
    "start_time": "2022-02-24T13:54:55.342Z"
   },
   {
    "duration": 12,
    "start_time": "2022-02-24T13:54:55.373Z"
   },
   {
    "duration": 66,
    "start_time": "2022-02-24T13:54:55.387Z"
   },
   {
    "duration": 23,
    "start_time": "2022-02-24T13:54:55.460Z"
   },
   {
    "duration": 8126,
    "start_time": "2022-02-24T13:54:55.488Z"
   },
   {
    "duration": 32,
    "start_time": "2022-02-24T13:55:03.617Z"
   },
   {
    "duration": 408,
    "start_time": "2022-02-24T13:55:03.653Z"
   },
   {
    "duration": 30,
    "start_time": "2022-02-24T13:55:04.065Z"
   },
   {
    "duration": 49,
    "start_time": "2022-02-24T13:55:04.099Z"
   },
   {
    "duration": 13,
    "start_time": "2022-02-24T13:55:04.152Z"
   },
   {
    "duration": 61,
    "start_time": "2022-02-24T13:55:04.168Z"
   },
   {
    "duration": 858,
    "start_time": "2022-02-24T13:55:04.233Z"
   },
   {
    "duration": 37,
    "start_time": "2022-02-24T13:55:05.093Z"
   },
   {
    "duration": 20,
    "start_time": "2022-02-24T13:55:05.132Z"
   },
   {
    "duration": 493,
    "start_time": "2022-02-24T13:55:05.154Z"
   },
   {
    "duration": 17,
    "start_time": "2022-02-24T13:55:05.649Z"
   },
   {
    "duration": 23,
    "start_time": "2022-02-24T13:55:05.669Z"
   },
   {
    "duration": 41,
    "start_time": "2022-02-24T13:55:05.694Z"
   },
   {
    "duration": 1492,
    "start_time": "2022-02-24T13:55:05.738Z"
   },
   {
    "duration": 835,
    "start_time": "2022-02-24T13:55:07.232Z"
   },
   {
    "duration": 534,
    "start_time": "2022-02-24T13:55:08.070Z"
   },
   {
    "duration": 27,
    "start_time": "2022-02-24T13:55:08.606Z"
   },
   {
    "duration": 625,
    "start_time": "2022-02-24T13:55:08.635Z"
   },
   {
    "duration": 6,
    "start_time": "2022-02-24T13:55:09.263Z"
   },
   {
    "duration": 22,
    "start_time": "2022-02-24T13:55:09.272Z"
   },
   {
    "duration": 107,
    "start_time": "2022-02-24T13:55:09.296Z"
   },
   {
    "duration": 34,
    "start_time": "2022-02-24T13:55:09.406Z"
   },
   {
    "duration": 976,
    "start_time": "2022-02-24T13:55:09.443Z"
   },
   {
    "duration": 807,
    "start_time": "2022-02-24T13:55:10.422Z"
   },
   {
    "duration": 20,
    "start_time": "2022-02-24T13:55:11.231Z"
   },
   {
    "duration": 347,
    "start_time": "2022-02-24T13:55:11.254Z"
   },
   {
    "duration": 31,
    "start_time": "2022-02-24T13:55:11.604Z"
   },
   {
    "duration": 28,
    "start_time": "2022-02-24T13:55:11.638Z"
   },
   {
    "duration": 33,
    "start_time": "2022-02-24T13:55:11.668Z"
   },
   {
    "duration": 32,
    "start_time": "2022-02-24T13:55:11.728Z"
   },
   {
    "duration": 17,
    "start_time": "2022-02-24T13:55:11.763Z"
   },
   {
    "duration": 50,
    "start_time": "2022-02-24T13:55:11.783Z"
   },
   {
    "duration": 5737,
    "start_time": "2022-02-24T13:56:31.176Z"
   },
   {
    "duration": 270,
    "start_time": "2022-02-24T13:56:36.648Z"
   },
   {
    "duration": 268,
    "start_time": "2022-02-24T13:56:36.652Z"
   },
   {
    "duration": 264,
    "start_time": "2022-02-24T13:56:36.657Z"
   },
   {
    "duration": 238,
    "start_time": "2022-02-24T13:56:36.685Z"
   },
   {
    "duration": 236,
    "start_time": "2022-02-24T13:56:36.688Z"
   },
   {
    "duration": 234,
    "start_time": "2022-02-24T13:56:36.692Z"
   },
   {
    "duration": 233,
    "start_time": "2022-02-24T13:56:36.695Z"
   },
   {
    "duration": 230,
    "start_time": "2022-02-24T13:56:36.700Z"
   },
   {
    "duration": 228,
    "start_time": "2022-02-24T13:56:36.703Z"
   },
   {
    "duration": 226,
    "start_time": "2022-02-24T13:56:36.707Z"
   },
   {
    "duration": 225,
    "start_time": "2022-02-24T13:56:36.710Z"
   },
   {
    "duration": 223,
    "start_time": "2022-02-24T13:56:36.713Z"
   },
   {
    "duration": 222,
    "start_time": "2022-02-24T13:56:36.716Z"
   },
   {
    "duration": 208,
    "start_time": "2022-02-24T13:56:36.731Z"
   },
   {
    "duration": 207,
    "start_time": "2022-02-24T13:56:36.734Z"
   },
   {
    "duration": 205,
    "start_time": "2022-02-24T13:56:36.737Z"
   },
   {
    "duration": 204,
    "start_time": "2022-02-24T13:56:36.740Z"
   },
   {
    "duration": 203,
    "start_time": "2022-02-24T13:56:36.743Z"
   },
   {
    "duration": 202,
    "start_time": "2022-02-24T13:56:36.746Z"
   },
   {
    "duration": 201,
    "start_time": "2022-02-24T13:56:36.749Z"
   },
   {
    "duration": 198,
    "start_time": "2022-02-24T13:56:36.754Z"
   },
   {
    "duration": 123,
    "start_time": "2022-02-24T13:56:36.831Z"
   },
   {
    "duration": 120,
    "start_time": "2022-02-24T13:56:36.837Z"
   },
   {
    "duration": 117,
    "start_time": "2022-02-24T13:56:36.842Z"
   },
   {
    "duration": 112,
    "start_time": "2022-02-24T13:56:36.849Z"
   },
   {
    "duration": 109,
    "start_time": "2022-02-24T13:56:36.854Z"
   },
   {
    "duration": 109,
    "start_time": "2022-02-24T13:56:36.857Z"
   },
   {
    "duration": 163,
    "start_time": "2022-02-24T13:56:36.863Z"
   },
   {
    "duration": 160,
    "start_time": "2022-02-24T13:56:36.868Z"
   },
   {
    "duration": 157,
    "start_time": "2022-02-24T13:56:36.872Z"
   },
   {
    "duration": 156,
    "start_time": "2022-02-24T13:56:36.875Z"
   },
   {
    "duration": 154,
    "start_time": "2022-02-24T13:56:36.878Z"
   },
   {
    "duration": 153,
    "start_time": "2022-02-24T13:56:36.881Z"
   },
   {
    "duration": 152,
    "start_time": "2022-02-24T13:56:36.884Z"
   },
   {
    "duration": -5,
    "start_time": "2022-02-24T13:56:37.042Z"
   },
   {
    "duration": -6,
    "start_time": "2022-02-24T13:56:37.045Z"
   },
   {
    "duration": -9,
    "start_time": "2022-02-24T13:56:37.049Z"
   },
   {
    "duration": -9,
    "start_time": "2022-02-24T13:56:37.052Z"
   },
   {
    "duration": -11,
    "start_time": "2022-02-24T13:56:37.055Z"
   },
   {
    "duration": -12,
    "start_time": "2022-02-24T13:56:37.058Z"
   },
   {
    "duration": -32,
    "start_time": "2022-02-24T13:56:37.080Z"
   },
   {
    "duration": -34,
    "start_time": "2022-02-24T13:56:37.083Z"
   },
   {
    "duration": -35,
    "start_time": "2022-02-24T13:56:37.086Z"
   },
   {
    "duration": -36,
    "start_time": "2022-02-24T13:56:37.089Z"
   },
   {
    "duration": -55,
    "start_time": "2022-02-24T13:56:37.109Z"
   },
   {
    "duration": -58,
    "start_time": "2022-02-24T13:56:37.114Z"
   },
   {
    "duration": -59,
    "start_time": "2022-02-24T13:56:37.117Z"
   },
   {
    "duration": -67,
    "start_time": "2022-02-24T13:56:37.126Z"
   },
   {
    "duration": -80,
    "start_time": "2022-02-24T13:56:37.141Z"
   },
   {
    "duration": -85,
    "start_time": "2022-02-24T13:56:37.149Z"
   },
   {
    "duration": -26,
    "start_time": "2022-02-24T13:56:37.152Z"
   },
   {
    "duration": -28,
    "start_time": "2022-02-24T13:56:37.155Z"
   },
   {
    "duration": -29,
    "start_time": "2022-02-24T13:56:37.158Z"
   },
   {
    "duration": -30,
    "start_time": "2022-02-24T13:56:37.161Z"
   },
   {
    "duration": -30,
    "start_time": "2022-02-24T13:56:37.163Z"
   }
  ],
  "colab": {
   "collapsed_sections": [],
   "name": "notebook (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
